{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a9236b7",
   "metadata": {},
   "source": [
    "# Final Report\n",
    "## Classification Analysis\n",
    "### Brandyn Waterman, 3/14/2022, Innis Cohort\n",
    "\n",
    "Good afternoon! We begin with imports that are needed for operating this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bb90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations and df manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visulaizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Math & Statistics\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "# SQL access\n",
    "from env import host, user, password\n",
    "\n",
    "# Imported modules acquire.py and prepare.py\n",
    "from acquire import get_telco_data\n",
    "from prepare import prep_telco\n",
    "\n",
    "# sklearn suite for modeling and analysis\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_graphviz, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898effe",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "The purpose of this project is to help reduce churn of customers at Telco. This report will go over the steps that were needed to obtain our **goals** of:\n",
    "- Identifying key drivers (acquire, prepare, explore)\n",
    "- Creating classification models for churn prediction (model)\n",
    "- Providing recommendations and solutions based on the information learned (summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38f054",
   "metadata": {},
   "source": [
    "### Planning:\n",
    "The first step in this journey is to establish an initial plan and question set to guide our interactions with the data. \n",
    "\n",
    "Some of the initial questions relating to the data are:\n",
    "- What is our current baseline of churn?\n",
    "- How does plan type (service) impact churn?\n",
    "- How does internet type impact churn?\n",
    "- Do any demographic attributes impact churn?\n",
    "- Does cost impact churn?\n",
    "- Does tenure impact churn?\n",
    "\n",
    "For business purposes:\n",
    "- How much is this churn costing Telco?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e770d",
   "metadata": {},
   "source": [
    "### Acquire:\n",
    "Under the hood our acquire module is making use of get_db_url() to access the SQL server with our credentials, and then get_telco_data() to query the SQL database for our data. \n",
    "\n",
    "Our query selects from customers, internet_service_types, contract_types, and payment_types tables from the 'telco-churn' database. It then converts the SQL response to a dataframe, and that dataframe into a local .csv file. (If the file already exists locally the function checks for this prior to the SQL query) The dataframe is then returned. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07741e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached csv\n"
     ]
    }
   ],
   "source": [
    "telco_data = get_telco_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4db3c",
   "metadata": {},
   "source": [
    "### Prepare:\n",
    "Under the hood our prepare module uses telco_split() to take in a dataframe and return three dataframes: train, validate, and test. These are a 56%, 24%, and 20% split of the prepared dataframe, respectfully. \n",
    "\n",
    "The prep_telco() function takes in our acquired dataframe and cleans it for use. \n",
    "\n",
    "The order of steps are as follows:\n",
    "\n",
    "To ensure we have no duplicates in our data: df = df.drop_duplicates(inplace=True)\n",
    "\n",
    "To remove some redundant columns (internet_service_type_id, contract_type_id, payment_type_id): df = df.drop(columns=['internet_service_type_id', contract_type_id', 'payment_type_id']) \n",
    "\n",
    "To fix the total_charges columns: df.total_charges = df.total_charges.replace(' ', np.nan).astype(float)\n",
    "- The issue we had was total_charges being the wrong datatype and having empty strings instead of NaN assignments\n",
    "\n",
    "To address these **missing values**: df.dropna(inplace=True)\n",
    "- In total there were 11 rows of missing total_charges values. These were due to the tenure of these customers being 0. Since this is a very small portion of the total dataset they were dropped. They did not have enough tenure to be considered relevant and they were causing missing values in the data. \n",
    "\n",
    "The data was then separated for categorical columns for encoding by checking if the dtype is 'O' (object): cat_cols = [col for col in df.columns if df[col].dtype == '0']\n",
    "- We want to ensure that our customer_id column does not get encoded so we remove it before the next step: cat_cols.remove('customer_id')\n",
    "\n",
    "To iterate through our categorical columns and encode them: \n",
    "```for col in cat_cols:\n",
    "    dummy_df = pd.get_dummies(df[col],\n",
    "    prefix = df[col].name,\n",
    "    drop_first = True,\n",
    "    dummy_na = False)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    df = df.drop(columns=col)\n",
    "    ```\n",
    "- This will create dummy columns, concat them to our dataframe, and drop the now redundant column.\n",
    "\n",
    "After our data is encoded the telco_split() function is utilized and our train, validate, and test dataframes are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118ee032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prep_telco(telco_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e91a82",
   "metadata": {},
   "source": [
    "### Explore:\n",
    "We now want to try and delve out as many of the questions we asked initially, and expand on any insights that present themselves from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd891270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
